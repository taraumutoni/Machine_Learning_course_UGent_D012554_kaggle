{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Eye blinking prediction.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "52xHOyHDXxao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goRLnuyRXxaw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<img src=\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_kaggle/master/header.png\" alt=\"drawing\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsJ4TbSlXxax",
        "colab_type": "text"
      },
      "source": [
        "A multi-channel electroencephalography (EEG) system enables a broad range of applications including neurotherapy, biofeedback, and brain computer interfacing. The dataset you will analyse is created with the [Emotiv EPOC+](https://www.emotiv.com/product/emotiv-epoc-14-channel-mobile-eeg).  \n",
        "\n",
        "It has 14 EEG channels with names based on the International 10-20 locations: AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, AF4:\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_kaggle/master/EEG.png\" alt=\"drawing\" width=\"200\"/>\n",
        "<center/>\n",
        "<br/>\n",
        "<br/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzXBqhLUfxyh",
        "colab_type": "text"
      },
      "source": [
        "All data is from one continuous EEG measurement with the Emotiv EEG Neuroheadset. \n",
        "\n",
        "The experiment was conducted on one person only. The duration of the measurement was around 117 seconds.\n",
        "\n",
        "From the paper:\n",
        "\n",
        "> *The experiment was carried out in a quiet room. During\n",
        "the experiment, the proband was being videotaped. To prevent\n",
        "artifacts, the proband was not aware of the exact start time\n",
        "of the measurement. Instead, he was told to sit relaxed, look\n",
        "straight to the camera, and change the eye state at free will.\n",
        "Only additional constraint was that, accumulated over the\n",
        "entire session, the duration of both eye states should be about\n",
        "the same and that the individual intervals should vary greatly\n",
        "in length (from eye blinking to longer stretches)...*\n",
        "\n",
        "The eye state was detected via a camera during the EEG measurement and later added manually to the file after analyzing the video frames. \n",
        "\n",
        "A label '1' indicates the eye-closed and '0' the eye-open state.\n",
        "\n",
        "(*Source: Oliver Roesler, Stuttgart, Germany*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rHopvjFXxay",
        "colab_type": "text"
      },
      "source": [
        "Let's load the train and test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw7NaXHYXxaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_kaggle/master/eeg_train.csv\")\n",
        "\n",
        "testset = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_kaggle/master/eeg_test.csv\")\n",
        "\n",
        "sample_submission = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_kaggle/master/sample_submission.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa4COLVgY48t",
        "colab_type": "text"
      },
      "source": [
        "You will fit a model on the trainset and make predictions on the testset. \n",
        "\n",
        "To submit these predictions to Kaggle you need to write a .csv file with two columns: \n",
        "- `index` that matches the `index` column in the test set.\n",
        "- `label` which is your prediction.\n",
        "\n",
        "Here is an example predictions file for Kaggle:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-pAX9vY-3vf",
        "colab_type": "code",
        "outputId": "cb8e7cc5-b4b2-4241-c563-2048f02b1c41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "trainset.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AF3</th>\n",
              "      <th>F7</th>\n",
              "      <th>F3</th>\n",
              "      <th>FC5</th>\n",
              "      <th>T7</th>\n",
              "      <th>P7</th>\n",
              "      <th>O1</th>\n",
              "      <th>02</th>\n",
              "      <th>P8</th>\n",
              "      <th>T8</th>\n",
              "      <th>FC6</th>\n",
              "      <th>F4</th>\n",
              "      <th>F8</th>\n",
              "      <th>AF4</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4299.49</td>\n",
              "      <td>3997.44</td>\n",
              "      <td>4277.95</td>\n",
              "      <td>4116.92</td>\n",
              "      <td>4353.85</td>\n",
              "      <td>4623.08</td>\n",
              "      <td>4100.00</td>\n",
              "      <td>4623.59</td>\n",
              "      <td>4202.56</td>\n",
              "      <td>4229.23</td>\n",
              "      <td>4211.79</td>\n",
              "      <td>4278.97</td>\n",
              "      <td>4600.00</td>\n",
              "      <td>4369.23</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4302.05</td>\n",
              "      <td>3985.64</td>\n",
              "      <td>4261.03</td>\n",
              "      <td>4129.74</td>\n",
              "      <td>4334.36</td>\n",
              "      <td>4615.38</td>\n",
              "      <td>4072.31</td>\n",
              "      <td>4585.64</td>\n",
              "      <td>4192.31</td>\n",
              "      <td>4225.13</td>\n",
              "      <td>4195.90</td>\n",
              "      <td>4283.08</td>\n",
              "      <td>4607.18</td>\n",
              "      <td>4358.46</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4321.03</td>\n",
              "      <td>4015.90</td>\n",
              "      <td>4265.13</td>\n",
              "      <td>4122.56</td>\n",
              "      <td>4333.33</td>\n",
              "      <td>4613.33</td>\n",
              "      <td>4072.82</td>\n",
              "      <td>4602.05</td>\n",
              "      <td>4192.31</td>\n",
              "      <td>4223.08</td>\n",
              "      <td>4155.38</td>\n",
              "      <td>4286.15</td>\n",
              "      <td>4608.21</td>\n",
              "      <td>4371.79</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4408.21</td>\n",
              "      <td>4104.10</td>\n",
              "      <td>4380.00</td>\n",
              "      <td>4232.31</td>\n",
              "      <td>4449.74</td>\n",
              "      <td>4750.26</td>\n",
              "      <td>4169.23</td>\n",
              "      <td>4731.28</td>\n",
              "      <td>4311.28</td>\n",
              "      <td>4352.31</td>\n",
              "      <td>4319.49</td>\n",
              "      <td>4388.21</td>\n",
              "      <td>4715.90</td>\n",
              "      <td>4464.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4347.18</td>\n",
              "      <td>3975.38</td>\n",
              "      <td>4266.67</td>\n",
              "      <td>4102.56</td>\n",
              "      <td>4333.33</td>\n",
              "      <td>4617.95</td>\n",
              "      <td>4097.44</td>\n",
              "      <td>4612.82</td>\n",
              "      <td>4210.77</td>\n",
              "      <td>4240.51</td>\n",
              "      <td>4248.21</td>\n",
              "      <td>4313.33</td>\n",
              "      <td>4664.10</td>\n",
              "      <td>4411.79</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       AF3       F7       F3      FC5  ...       F4       F8      AF4  label\n",
              "0  4299.49  3997.44  4277.95  4116.92  ...  4278.97  4600.00  4369.23      1\n",
              "1  4302.05  3985.64  4261.03  4129.74  ...  4283.08  4607.18  4358.46      0\n",
              "2  4321.03  4015.90  4265.13  4122.56  ...  4286.15  4608.21  4371.79      0\n",
              "3  4408.21  4104.10  4380.00  4232.31  ...  4388.21  4715.90  4464.10      0\n",
              "4  4347.18  3975.38  4266.67  4102.56  ...  4313.33  4664.10  4411.79      1\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu2xlN7QAA0L",
        "colab_type": "code",
        "outputId": "0a387565-2576-4bff-e84e-c4d4bc2cef13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "testset.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AF3</th>\n",
              "      <th>F7</th>\n",
              "      <th>F3</th>\n",
              "      <th>FC5</th>\n",
              "      <th>T7</th>\n",
              "      <th>P7</th>\n",
              "      <th>O1</th>\n",
              "      <th>02</th>\n",
              "      <th>P8</th>\n",
              "      <th>T8</th>\n",
              "      <th>FC6</th>\n",
              "      <th>F4</th>\n",
              "      <th>F8</th>\n",
              "      <th>AF4</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4296.41</td>\n",
              "      <td>4040.51</td>\n",
              "      <td>4253.33</td>\n",
              "      <td>4124.10</td>\n",
              "      <td>4341.54</td>\n",
              "      <td>4618.46</td>\n",
              "      <td>4075.38</td>\n",
              "      <td>4601.03</td>\n",
              "      <td>4183.59</td>\n",
              "      <td>4204.10</td>\n",
              "      <td>4197.44</td>\n",
              "      <td>4268.72</td>\n",
              "      <td>4598.46</td>\n",
              "      <td>4342.56</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4291.28</td>\n",
              "      <td>3994.36</td>\n",
              "      <td>4247.18</td>\n",
              "      <td>4102.56</td>\n",
              "      <td>4328.21</td>\n",
              "      <td>4616.41</td>\n",
              "      <td>4057.44</td>\n",
              "      <td>4622.56</td>\n",
              "      <td>4198.46</td>\n",
              "      <td>4227.69</td>\n",
              "      <td>4190.77</td>\n",
              "      <td>4260.51</td>\n",
              "      <td>4593.33</td>\n",
              "      <td>4337.95</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4299.49</td>\n",
              "      <td>4019.49</td>\n",
              "      <td>4269.74</td>\n",
              "      <td>4116.41</td>\n",
              "      <td>4344.10</td>\n",
              "      <td>4635.38</td>\n",
              "      <td>4067.18</td>\n",
              "      <td>4627.18</td>\n",
              "      <td>4211.28</td>\n",
              "      <td>4233.33</td>\n",
              "      <td>4202.56</td>\n",
              "      <td>4280.51</td>\n",
              "      <td>4596.92</td>\n",
              "      <td>4350.26</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4280.00</td>\n",
              "      <td>4004.62</td>\n",
              "      <td>4263.59</td>\n",
              "      <td>4120.51</td>\n",
              "      <td>4323.59</td>\n",
              "      <td>4603.08</td>\n",
              "      <td>4040.51</td>\n",
              "      <td>4589.23</td>\n",
              "      <td>4174.87</td>\n",
              "      <td>4212.82</td>\n",
              "      <td>4192.82</td>\n",
              "      <td>4271.79</td>\n",
              "      <td>4608.72</td>\n",
              "      <td>4344.10</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4317.44</td>\n",
              "      <td>3968.72</td>\n",
              "      <td>4260.51</td>\n",
              "      <td>4101.54</td>\n",
              "      <td>4341.54</td>\n",
              "      <td>4600.51</td>\n",
              "      <td>4071.28</td>\n",
              "      <td>4607.69</td>\n",
              "      <td>4191.28</td>\n",
              "      <td>4231.28</td>\n",
              "      <td>4199.49</td>\n",
              "      <td>4282.05</td>\n",
              "      <td>4592.31</td>\n",
              "      <td>4372.82</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       AF3       F7       F3      FC5  ...       F4       F8      AF4  index\n",
              "0  4296.41  4040.51  4253.33  4124.10  ...  4268.72  4598.46  4342.56      0\n",
              "1  4291.28  3994.36  4247.18  4102.56  ...  4260.51  4593.33  4337.95      1\n",
              "2  4299.49  4019.49  4269.74  4116.41  ...  4280.51  4596.92  4350.26      2\n",
              "3  4280.00  4004.62  4263.59  4120.51  ...  4271.79  4608.72  4344.10      3\n",
              "4  4317.44  3968.72  4260.51  4101.54  ...  4282.05  4592.31  4372.82      4\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2Xcd8tvkEqA",
        "colab_type": "code",
        "outputId": "58f57531-751b-4301-945e-78260c6190bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "sample_submission.head(10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.168801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.124169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.947757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.069585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.635325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.659027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.653697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0.850030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.160489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0.843272</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index     label\n",
              "0      0  0.168801\n",
              "1      1  0.124169\n",
              "2      2  0.947757\n",
              "3      3  0.069585\n",
              "4      4  0.635325\n",
              "5      5  0.659027\n",
              "6      6  0.653697\n",
              "7      7  0.850030\n",
              "8      8  0.160489\n",
              "9      9  0.843272"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7AHk-3elWpy",
        "colab_type": "text"
      },
      "source": [
        "Make sure to save your results without the extra Pandas index column that is written by default:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ny3rYGokLiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"my_prediction_results.csv\"\n",
        "\n",
        "#make sure to not write the Pandas index column (index=False)\n",
        "sample_submission.to_csv(filename,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD8sr-WobM6K",
        "colab_type": "text"
      },
      "source": [
        "Notice that this predictions file is saved on the cloud server machine. To download this file to your local machine you need to click the \"Files\" icon that you find in the sidebar on the left.\n",
        "\n",
        "Submit this file to the [Kaggle competition website](https://www.kaggle.com/t/09885716fbf14eb08cc1cee2c9ebe7cc) to get an evaluation of your predictions on the public leaderboard.\n",
        "\n",
        "For the report I want you to write a notebook with a scientific description of your analysis. You have to compare the prediction performance of your two best prediction models. This includes data pre-processing, hyperparameter tuning and model evaluation. I also want you to compare the actual predictions made by each model.\n",
        "\n",
        "To create a new notebook go the \"File\" in the menu bar and click \"New notebook\". Do not forget to save your notebook to your GitHub account. You can create as many notebook as you want, but the final report should be in a notebook with the name \"Kaggle_eye_blinking_prediciton.ipynb\"\n",
        "\n",
        "You will be evaluated (equal points) on clarity of the report, scientific insight and complexity of the analysis. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUNZKOnDY51C",
        "colab_type": "text"
      },
      "source": [
        "**1.Pre-processing**\n",
        "\n",
        "In this step we try to transform the feature values by removing the mean value and dividing it by their standard deviation. Otherwise features with big variance bigger than other might suppress the others in the background and make sit difficult for the estimator to learn correctly from other features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtFI5qAKr7QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset_copy = trainset.copy()\n",
        "testset_copy = testset.copy()\n",
        "label_column = trainset.pop('label')\n",
        "index_column = testset.pop('index')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMJt-T564p7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler #pre-processing step where we center all the feature values around O\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(trainset)\n",
        "trainset_scaled = scaler.transform(trainset)\n",
        "testset_scaled = scaler.transform(testset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a34Fqgdp4tIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset_scaled= pd.DataFrame(data=trainset_scaled)\n",
        "testset_scaled = pd.DataFrame(data=testset_scaled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxmaodl2YIEP",
        "colab_type": "text"
      },
      "source": [
        "I plotted the labels to visualize their count, because in order to work with KNeighborclassifier they have to appear in an average equal amount otherwise the classifier might always favorise one class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f91XImPZ7urP",
        "colab_type": "code",
        "outputId": "34cef1d0-9513-4c90-822b-dd5ccf6944de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import seaborn as sns\n",
        "sns.countplot(x='label', data=trainset_copy,palette='hls')\n",
        "plt.show() # Plotting the ratio of the labels, because it might influence the KNeighbormodel fitting if the dataset consist mostly of one label;"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZE1O3obZB4W",
        "colab_type": "text"
      },
      "source": [
        "The KNN classifier gets fitted on the training data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX5hUP9Uah39",
        "colab_type": "text"
      },
      "source": [
        "# 2.KNeighborsClassifier\n",
        "\n",
        "KNeighborsClassifier works with a hyperparameter K, a neighbor value that assigns how many neighbors the new data point will be compared to in order to be classified. By applying GridsearchCV we can obtain what the optimal K is in this instance. This classifier memorizes the labels of the training data and will try link the new data point to closest label. If one data point is mislabelled and K=1 this means that unseen data points will only rely on one point and be labelled as such. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cChIyRJIaTD5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2336a922-9673-4f2b-958d-6f3845b1f0f5"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier # hypertuning in finding the optimal n_neighbor value\n",
        "\n",
        "#create new a knn model\n",
        "knn2 = KNeighborsClassifier()\n",
        "#create a dictionary of all values we want to test for n_neighbors\n",
        "param_grid = {'n_neighbors': np.arange(1, 25)}\n",
        "#use gridsearch to test all values for n_neighbors\n",
        "knn_gscv = GridSearchCV(knn2, param_grid, cv=10)\n",
        "#fit model to data\n",
        "knn_gscv.fit(trainset_scaled, label_column)\n",
        "knn_gscv.best_params_"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_neighbors': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hsyMSpd5ILC",
        "colab_type": "code",
        "outputId": "219218c1-c79b-45ba-e4b7-d22122ddc256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#KNeighboring model \n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=1)# classifier should be looking for the 1 nearest neighbor\n",
        "knn.fit(trainset_scaled, label_column)#knn is fitted on features and response of training dataset"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJb0GzB3eW2q",
        "colab_type": "text"
      },
      "source": [
        "After fitting the model on trainingset, we can then fit it on the testdata and make predictions about. In this case I implemented the predict function that predicted for each index of the test data the label value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki0-3e336o0d",
        "colab_type": "code",
        "outputId": "8c8847dc-ab78-49c6-b74c-95a8e5b4d179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "knn.predict(testset_scaled)#After making a model with training data, next step is to fit the model on unseen data(test)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmwBJDLifUer",
        "colab_type": "text"
      },
      "source": [
        "# 3.Support Vector Machine\n",
        "SVM works with a hyperplane in N-dimensions(N= amount of features). We had 14 features that contributed to the labelling of all the observations. SVM will classify training data by a hyperplane that is specified by support vectors because these data points decide where the boundary should be set and are closest to the decision plane.  In svm we want to find a hyperplane that is as far from one class as the other, creating a maximal margin that cleary sets a boundary between the classes.  \n",
        "\n",
        "In case of a data that is linearly non separable we can use the kernel function radial basis function 'rbf'. This kernel can separate data points by transforming the vectors in higher dimension. In the RBF kernel there a two parameters that need to be tuned in order to optimize the generalization performance of our model. The fist parameter is Gamma, that determines how far the data points need to be in order to participate in making a decision boundary. A high gamma will only select support vectors because these points lay closer to the hyperplane, while as a lower gamma would take further laying training data into the model fitting. As for C , the penalty value for misclassification when overfitting the training data. A high C value will penalize our model for each misclassified point in away that the classifier will want to avoid this and starts to overfit the training data and perform less on unseen data.\n",
        "\n",
        "For model tuning I computed via GridsearchCV the values for the hyperparameters gamma and C."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsWqZWPa7hda",
        "colab_type": "code",
        "outputId": "72b6c8bc-2732-41f6-d2a3-821aa1b19925",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#SVM \n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV # tried the gridsearch for C and gamma value\n",
        "\n",
        "c_value = [0.001,0.01,0.1,1,10,100]\n",
        "gamma_value = [0.001,0.01,0.1,1,10,100]\n",
        "clf = svm.SVC() #estimator\n",
        "params = dict(C=c_value, gamma=gamma_value )# grid of parameters you want to search the optimal value\n",
        "grid_search = GridSearchCV(clf, param_grid=params, cv=10)\n",
        "grid_search.fit(trainset_scaled, label_column)\n",
        "\n",
        "print(grid_search.best_params_)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'C': 10, 'gamma': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofOWWMc47k_2",
        "colab_type": "code",
        "outputId": "e452dd8b-b957-46ad-e04b-b19493983e8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "clf = svm.SVC(C= 10, kernel='rbf',gamma=1, probability=True) \n",
        " #gamma scales the influence two observations have on each other depending on the distance\n",
        "clf.fit(trainset_scaled, label_column)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
              "    probability=True, random_state=None, shrinking=True, tol=0.001,\n",
              "    verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPX4rE_U7n8y",
        "colab_type": "code",
        "outputId": "2bc27a75-773a-4b5e-809c-0950bd2e2124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "clf.predict_proba(testset_scaled)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99676376, 0.00323624],\n",
              "       [0.63386273, 0.36613727],\n",
              "       [0.99350001, 0.00649999],\n",
              "       ...,\n",
              "       [0.10807878, 0.89192122],\n",
              "       [0.04935172, 0.95064828],\n",
              "       [0.99546703, 0.00453297]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tbVReQ9oIvl",
        "colab_type": "text"
      },
      "source": [
        "Two models were used so we can eventually compare their prediction with true value of training data. In this part ROC curve will be plotted to show the prediction performance of the estimators of KNN and SVM algorithms. The scaled trainset will be splitted in 80% training dataset and 20% as test to evaluate the estimators performance on unseen data. I used a randomstate value of 4 so that the split function would generate each time the same results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MupWAcVooDg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "# shuffle and split training and into subset of train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(trainset_scaled, label_column, test_size=.2,\n",
        "                                                    random_state=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkUUjQpKc_mX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = svm.SVC(C= 10, kernel='rbf',gamma=1, probability=True) \n",
        " #gamma scales the influence two observations have on each other depending on the distance\n",
        "clf.fit(X_train, y_train)\n",
        "svm_predict = clf.decision_function(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FVVrQXUdSPk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "fdfdcd0e-5563-4b9e-e715-fe0a22c7394f"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=1)# classifier should be looking for the 1 nearest neighbor\n",
        "knn.fit(X_train, y_train)\n",
        "Knn_predict = knn.predict(X_test)\n",
        "print(Knn_predict)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 1 0 1\n",
            " 0 0 1 1 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1\n",
            " 0 0 0 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0\n",
            " 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0\n",
            " 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 1 0\n",
            " 0 1 1 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 1 0 1 0 1 0 0 1 1 0 0 0 0\n",
            " 1 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1\n",
            " 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1\n",
            " 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0\n",
            " 1 1 0 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0\n",
            " 1 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8wMMMG-d-8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "529c8f59-3fdf-470a-e56f-7c8e672426b8"
      },
      "source": [
        "#Plotting ROC and compare the AUC of the classifiers\n",
        "#Knn_fpr, Knn_tpr, threshold = roc_curve(y_test,Knn_predict) # ROC curve of KNN\n",
        "#Knn_auc = auc(Knn_fpr, Knn_tpr) \n",
        "\n",
        "svm_fpr, svm_tpr, threshold = roc_curve(y_test,svm_predict) # ROC curve of SVM\n",
        "svm_auc = auc(svm_fpr, svm_tpr)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "#plt.plot(Knn_fpr, Knn_tpr, linestyle='-', label='KNN (auc=%0.3f)'% Knn_auc)\n",
        "plt.plot(svm_fpr, svm_tpr, linestyle='--', label='SVM (auc=%0.3f)'% svm_auc)\n",
        "\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn2O50BTlgiV",
        "colab_type": "text"
      },
      "source": [
        "# Conclusions\n",
        "\n",
        "I was not able to plot the ROC of KNN since it doesn' make predictions in probability values,but only classifies unseen data based on the neighbor(class) that occurs the most. With Support vector machine we obtained an AUC of 0,96 indicating that the classifier would able to classify observations in their true category minimizing misclassification."
      ]
    }
  ]
}