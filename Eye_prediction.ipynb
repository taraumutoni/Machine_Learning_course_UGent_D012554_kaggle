{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eye_prediction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOsmKY+CDut+V0oA9sIdsAa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taraumutoni/Machine_Learning_course_UGent_D012554_kaggle/blob/master/Eye_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s07iHxR8zzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA2Rc_4I-Pxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_kaggle/master/eeg_train.csv\")\n",
        "\n",
        "testset = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_kaggle/master/eeg_test.csv\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vDNOKC--TbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset_copy = trainset.copy()\n",
        "testset_copy = testset.copy()\n",
        "label_column = trainset.pop('label')\n",
        "index_column = testset.pop('index')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhCcxBps-f4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1.Start of by weighing all features at the same scale\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(trainset)\n",
        "trainset_scaled = scaler.transform(trainset)\n",
        "testset_scaled = scaler.transform(testset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z-L5zqyABt9",
        "colab_type": "code",
        "outputId": "2e6a83a0-815e-4c0c-b5c0-56be6356b145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "trainset_scaled= pd.DataFrame(data=trainset_scaled)\n",
        "trainset_scaled"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.018351</td>\n",
              "      <td>-0.396476</td>\n",
              "      <td>0.677912</td>\n",
              "      <td>-0.277047</td>\n",
              "      <td>0.733699</td>\n",
              "      <td>0.167400</td>\n",
              "      <td>1.330668</td>\n",
              "      <td>0.454721</td>\n",
              "      <td>0.093570</td>\n",
              "      <td>-0.068336</td>\n",
              "      <td>0.418469</td>\n",
              "      <td>0.026714</td>\n",
              "      <td>-0.156365</td>\n",
              "      <td>0.252992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.052070</td>\n",
              "      <td>-0.791842</td>\n",
              "      <td>-0.136210</td>\n",
              "      <td>0.346482</td>\n",
              "      <td>-0.434286</td>\n",
              "      <td>-0.259658</td>\n",
              "      <td>0.007585</td>\n",
              "      <td>-1.609301</td>\n",
              "      <td>-0.482085</td>\n",
              "      <td>-0.276922</td>\n",
              "      <td>-0.232997</td>\n",
              "      <td>0.235973</td>\n",
              "      <td>0.060820</td>\n",
              "      <td>-0.037576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.574178</td>\n",
              "      <td>0.222036</td>\n",
              "      <td>0.061066</td>\n",
              "      <td>-0.002733</td>\n",
              "      <td>-0.496011</td>\n",
              "      <td>-0.373355</td>\n",
              "      <td>0.031954</td>\n",
              "      <td>-0.716795</td>\n",
              "      <td>-0.482085</td>\n",
              "      <td>-0.381214</td>\n",
              "      <td>-1.894254</td>\n",
              "      <td>0.392280</td>\n",
              "      <td>0.091976</td>\n",
              "      <td>0.322059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.972354</td>\n",
              "      <td>3.177226</td>\n",
              "      <td>5.588146</td>\n",
              "      <td>5.335202</td>\n",
              "      <td>6.480134</td>\n",
              "      <td>7.221060</td>\n",
              "      <td>4.638614</td>\n",
              "      <td>6.311759</td>\n",
              "      <td>6.199439</td>\n",
              "      <td>6.193291</td>\n",
              "      <td>4.834001</td>\n",
              "      <td>5.588622</td>\n",
              "      <td>3.349453</td>\n",
              "      <td>2.812530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.293521</td>\n",
              "      <td>-1.135609</td>\n",
              "      <td>0.135164</td>\n",
              "      <td>-0.975478</td>\n",
              "      <td>-0.496011</td>\n",
              "      <td>-0.117120</td>\n",
              "      <td>1.208346</td>\n",
              "      <td>-0.131037</td>\n",
              "      <td>0.554655</td>\n",
              "      <td>0.505527</td>\n",
              "      <td>1.911632</td>\n",
              "      <td>1.776139</td>\n",
              "      <td>1.782573</td>\n",
              "      <td>1.401236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>-2.430832</td>\n",
              "      <td>0.222036</td>\n",
              "      <td>-1.616738</td>\n",
              "      <td>-0.725969</td>\n",
              "      <td>-0.311435</td>\n",
              "      <td>0.167400</td>\n",
              "      <td>-0.017261</td>\n",
              "      <td>-0.521542</td>\n",
              "      <td>-0.741551</td>\n",
              "      <td>-0.276922</td>\n",
              "      <td>-1.347334</td>\n",
              "      <td>-1.931461</td>\n",
              "      <td>-1.831536</td>\n",
              "      <td>-2.555566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>-0.864783</td>\n",
              "      <td>0.874724</td>\n",
              "      <td>-1.246726</td>\n",
              "      <td>-0.476460</td>\n",
              "      <td>0.272258</td>\n",
              "      <td>-0.060549</td>\n",
              "      <td>-0.286752</td>\n",
              "      <td>-0.660775</td>\n",
              "      <td>-0.453442</td>\n",
              "      <td>-0.824839</td>\n",
              "      <td>-0.485547</td>\n",
              "      <td>-1.409078</td>\n",
              "      <td>-0.559580</td>\n",
              "      <td>-1.033657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>-0.342950</td>\n",
              "      <td>-0.053044</td>\n",
              "      <td>0.159704</td>\n",
              "      <td>0.272067</td>\n",
              "      <td>-0.126858</td>\n",
              "      <td>-0.487052</td>\n",
              "      <td>-1.683418</td>\n",
              "      <td>-0.633038</td>\n",
              "      <td>-1.086943</td>\n",
              "      <td>-0.120228</td>\n",
              "      <td>-0.359272</td>\n",
              "      <td>-0.913170</td>\n",
              "      <td>-0.233802</td>\n",
              "      <td>-0.175981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>-0.060714</td>\n",
              "      <td>0.754439</td>\n",
              "      <td>0.579275</td>\n",
              "      <td>1.219520</td>\n",
              "      <td>1.440242</td>\n",
              "      <td>0.707600</td>\n",
              "      <td>1.011962</td>\n",
              "      <td>2.769472</td>\n",
              "      <td>0.611940</td>\n",
              "      <td>-0.120228</td>\n",
              "      <td>0.376650</td>\n",
              "      <td>0.053189</td>\n",
              "      <td>-0.032346</td>\n",
              "      <td>-0.521857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>0.080403</td>\n",
              "      <td>0.033065</td>\n",
              "      <td>0.332440</td>\n",
              "      <td>1.244811</td>\n",
              "      <td>1.071689</td>\n",
              "      <td>-0.373355</td>\n",
              "      <td>0.252707</td>\n",
              "      <td>0.231731</td>\n",
              "      <td>-0.798835</td>\n",
              "      <td>0.244542</td>\n",
              "      <td>0.650110</td>\n",
              "      <td>0.157564</td>\n",
              "      <td>0.650366</td>\n",
              "      <td>-0.286596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows Ã— 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2   ...        11        12        13\n",
              "0    -0.018351 -0.396476  0.677912  ...  0.026714 -0.156365  0.252992\n",
              "1     0.052070 -0.791842 -0.136210  ...  0.235973  0.060820 -0.037576\n",
              "2     0.574178  0.222036  0.061066  ...  0.392280  0.091976  0.322059\n",
              "3     2.972354  3.177226  5.588146  ...  5.588622  3.349453  2.812530\n",
              "4     1.293521 -1.135609  0.135164  ...  1.776139  1.782573  1.401236\n",
              "...        ...       ...       ...  ...       ...       ...       ...\n",
              "1995 -2.430832  0.222036 -1.616738  ... -1.931461 -1.831536 -2.555566\n",
              "1996 -0.864783  0.874724 -1.246726  ... -1.409078 -0.559580 -1.033657\n",
              "1997 -0.342950 -0.053044  0.159704  ... -0.913170 -0.233802 -0.175981\n",
              "1998 -0.060714  0.754439  0.579275  ...  0.053189 -0.032346 -0.521857\n",
              "1999  0.080403  0.033065  0.332440  ...  0.157564  0.650366 -0.286596\n",
              "\n",
              "[2000 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMO0iDqJCIcn",
        "colab_type": "code",
        "outputId": "6277d19f-10e8-41d1-92e2-309dc4a14b39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "testset_scaled = pd.DataFrame(data=testset_scaled)\n",
        "testset_scaled.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.103077</td>\n",
              "      <td>1.046608</td>\n",
              "      <td>-0.506702</td>\n",
              "      <td>0.072168</td>\n",
              "      <td>-0.004007</td>\n",
              "      <td>-0.088835</td>\n",
              "      <td>0.154276</td>\n",
              "      <td>-0.772271</td>\n",
              "      <td>-0.971812</td>\n",
              "      <td>-1.346811</td>\n",
              "      <td>-0.169859</td>\n",
              "      <td>-0.495161</td>\n",
              "      <td>-0.202948</td>\n",
              "      <td>-0.466549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.244195</td>\n",
              "      <td>-0.499673</td>\n",
              "      <td>-0.802616</td>\n",
              "      <td>-0.975478</td>\n",
              "      <td>-0.802839</td>\n",
              "      <td>-0.202532</td>\n",
              "      <td>-0.702932</td>\n",
              "      <td>0.398702</td>\n",
              "      <td>-0.136692</td>\n",
              "      <td>-0.146683</td>\n",
              "      <td>-0.443319</td>\n",
              "      <td>-0.913170</td>\n",
              "      <td>-0.358124</td>\n",
              "      <td>-0.590924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.018351</td>\n",
              "      <td>0.342321</td>\n",
              "      <td>0.282880</td>\n",
              "      <td>-0.301852</td>\n",
              "      <td>0.149407</td>\n",
              "      <td>0.849583</td>\n",
              "      <td>-0.237536</td>\n",
              "      <td>0.649974</td>\n",
              "      <td>0.583297</td>\n",
              "      <td>0.140249</td>\n",
              "      <td>0.040053</td>\n",
              "      <td>0.105122</td>\n",
              "      <td>-0.249531</td>\n",
              "      <td>-0.258808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.554489</td>\n",
              "      <td>-0.155906</td>\n",
              "      <td>-0.013033</td>\n",
              "      <td>-0.102439</td>\n",
              "      <td>-1.079704</td>\n",
              "      <td>-0.941841</td>\n",
              "      <td>-1.511881</td>\n",
              "      <td>-1.414048</td>\n",
              "      <td>-1.461540</td>\n",
              "      <td>-0.903186</td>\n",
              "      <td>-0.359272</td>\n",
              "      <td>-0.338853</td>\n",
              "      <td>0.107403</td>\n",
              "      <td>-0.425001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.475423</td>\n",
              "      <td>-1.358756</td>\n",
              "      <td>-0.161230</td>\n",
              "      <td>-1.025087</td>\n",
              "      <td>-0.004007</td>\n",
              "      <td>-1.084378</td>\n",
              "      <td>-0.041630</td>\n",
              "      <td>-0.410047</td>\n",
              "      <td>-0.539931</td>\n",
              "      <td>0.035956</td>\n",
              "      <td>-0.085812</td>\n",
              "      <td>0.183531</td>\n",
              "      <td>-0.388978</td>\n",
              "      <td>0.349848</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        11        12        13\n",
              "0 -0.103077  1.046608 -0.506702  ... -0.495161 -0.202948 -0.466549\n",
              "1 -0.244195 -0.499673 -0.802616  ... -0.913170 -0.358124 -0.590924\n",
              "2 -0.018351  0.342321  0.282880  ...  0.105122 -0.249531 -0.258808\n",
              "3 -0.554489 -0.155906 -0.013033  ... -0.338853  0.107403 -0.425001\n",
              "4  0.475423 -1.358756 -0.161230  ...  0.183531 -0.388978  0.349848\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkDXS5oGBXnv",
        "colab_type": "code",
        "outputId": "14f9d6b4-a618-47aa-d9ec-b0d3965e8978",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "import seaborn as sns;\n",
        "import matplotlib.pyplot as plt;\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.model_selection import cross_val_score \n",
        "import numpy as np\n",
        "\n",
        "model = LogisticRegression(C=1) #we want to compute a logistic function that predicts well the label for our training points\n",
        "model.fit(trainset_scaled,label_column)# fitting logistic regression on trainingset\n",
        "\n",
        "\n",
        "#predictions = model.predict_proba(trainset_scaled)[:,1]\n",
        "\n",
        "#print(\"R-squared = {}\".format(metrics.r2_score(label_column,predictions)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY3KU9MMMX3v",
        "colab_type": "code",
        "outputId": "74b0ce6f-6ff9-4cf9-cf70-2cf15832e6d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "score_acc = cross_val_score(model, trainset_scaled, label_column, scoring='roc_auc', cv=10).mean() # measure the auc score \n",
        "print(score_acc)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6593382417786088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qr2gwdYHdx9",
        "colab_type": "code",
        "outputId": "beb58122-c21b-4cf7-9f53-0e6e0355bfe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "search_space = [0.001,0.01,0.1,1,10,100] #C hyperparameter, previous model I used 1\n",
        "\n",
        "\n",
        "model = LogisticRegression()\n",
        "params = dict(C=search_space)\n",
        "grid_search = GridSearchCV(model, param_grid=params) # model is estimator\n",
        "grid_search.fit(trainset_scaled, label_column) # C-values overlopen op je trainingset \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(grid_search.best_estimator_) "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O9rfLldM-wo",
        "colab_type": "code",
        "outputId": "f78a036c-b87a-41dc-c3f1-d13238f2c7c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "model = LogisticRegression( C=100)\n",
        "model.fit(trainset_scaled,label_column)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx9FE2O7PWw3",
        "colab_type": "code",
        "outputId": "150d2694-585d-4507-f04e-268936e8425e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "predictions = model.predict_proba(testset_scaled)\n",
        "\n",
        "print(predictions)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.76329792 0.23670208]\n",
            " [0.64229297 0.35770703]\n",
            " [0.68605999 0.31394001]\n",
            " ...\n",
            " [0.52637569 0.47362431]\n",
            " [0.36303085 0.63696915]\n",
            " [0.57893101 0.42106899]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_Idkovg6QNE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ccdccecb-d3b5-401b-aba3-24b0d47d2951"
      },
      "source": [
        "model.predict(trainset_scaled)# predict the label on trainingset"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSubhbkX6kim",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "98700d54-a771-42c8-a4a1-a4ca37ea9bfe"
      },
      "source": [
        "train_respons = model.predict(trainset_scaled)\n",
        "len(train_respons)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs3JaC7S7ayM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "821c601f-b434-49be-d446-fba5b7d0b995"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "score_acc = accuracy_score(label_column,train_respons)# train accuracy\n",
        "\n",
        "print(score_acc) #accuracy of true value vs the model prediction"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn8sKMz6NQDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_test = pd.DataFrame(columns=['index','label'])\n",
        "prediction_test['index'] = index_column\n",
        "prediction_test['label'] = predictions[:,1] # all rows and column 1\n",
        "\n",
        " \n",
        "\n",
        "filename = \"Eye_prediction_Logistic_regression.csv\"\n",
        "prediction_test.to_csv(filename, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}